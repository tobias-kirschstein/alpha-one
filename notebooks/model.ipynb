{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN model to precict true state given observations\n",
    "# Input: obervation: observations in some time step of the game\n",
    "#        legal_masks: possible child states\n",
    "# output size: get_all_states() see imperfect information games notebook\n",
    "# I am not sure about the loss function for now. So, this notebook is in progress. Not fully completed\n",
    "\n",
    "\n",
    "import collections\n",
    "import functools\n",
    "import os\n",
    "from typing import Sequence\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "def cascade(x, fns):\n",
    "    for fn in fns:\n",
    "        x = fn(x)\n",
    "    return x\n",
    "\n",
    "tfkl = tf.keras.layers\n",
    "\n",
    "class TrainInput(collections.namedtuple(\"TrainInput\", \"observation legals_mask state\")):\n",
    "    # Inputs for training the Model.\n",
    "\n",
    "    @staticmethod\n",
    "    def stack(train_inputs):\n",
    "        observation, legals_mask, state = zip(*train_inputs)\n",
    "        return TrainInput(\n",
    "                        np.array(observation, dtype=np.float32),\n",
    "                        np.array(legals_mask, dtype=np.bool),\n",
    "                        np.array(state))\n",
    "\n",
    "\n",
    "class Losses(collections.namedtuple(\"Losses\", \"state l2\")):\n",
    "# Losses from a training step.\n",
    "\n",
    "    @property\n",
    "    def total(self):\n",
    "        return self.state + self.l2\n",
    "\n",
    "    def __str__(self):\n",
    "        return (\"Losses(total: {:.3f}, state: {:.3f},\"\n",
    "                    \"l2: {:.3f})\").format(self.total, self.state, self.l2)\n",
    "\n",
    "    def __add__(self, other):\n",
    "        return Losses(self.state + other.state,\n",
    "                      self.l2 + other.l2)\n",
    "\n",
    "    def __truediv__(self, n):\n",
    "        return Losses(self.state / n, self.l2 / n)\n",
    "\n",
    "class Model(object):\n",
    "\n",
    "    def __init__(self, session, saver, path):\n",
    "        # Init a model. Use build_model, from_checkpoint or from_graph instead.\"\"\"\n",
    "        self._session = session\n",
    "        self._saver = saver\n",
    "        self._path = path\n",
    "        \n",
    "        def get_var(name):\n",
    "            return self._session.graph.get_tensor_by_name(name + \":0\")\n",
    "\n",
    "        self._input = get_var(\"input\")\n",
    "        self._legals_mask = get_var(\"legals_mask\")\n",
    "        self._training = get_var(\"training\")\n",
    "        self._state_softmax = get_var(\"state_softmax\")\n",
    "        self._state_loss = get_var(\"state_loss\")\n",
    "        self._l2_reg_loss = get_var(\"l2_reg_loss\")\n",
    "        self._state_targets = get_var(\"state_targets\")\n",
    "        self._train = self._session.graph.get_operation_by_name(\"train\")\n",
    "\n",
    "    @classmethod\n",
    "    def build_model(cls, model_type, input_shape, output_size, nn_width, nn_depth,\n",
    "                  weight_decay, learning_rate, path):\n",
    "        \n",
    "        # Build a model with the specified params.\n",
    "\n",
    "        g = tf.Graph() \n",
    "        with g.as_default():\n",
    "            cls._define_graph(model_type, input_shape, output_size, nn_width,\n",
    "                              nn_depth, weight_decay, learning_rate)\n",
    "            init = tf.variables_initializer(tf.global_variables(),\n",
    "                                      name=\"init_all_vars_op\")\n",
    "            with tf.device(\"/cpu:0\"):  # Saver only works on CPU.\n",
    "                saver = tf.train.Saver(\n",
    "                    max_to_keep=10000, sharded=False, name=\"saver\")\n",
    "        session = tf.Session(graph=g)\n",
    "        session.__enter__()\n",
    "        session.run(init)\n",
    "        return cls(session, saver, path)\n",
    "\n",
    "    @classmethod\n",
    "    def from_checkpoint(cls, checkpoint, path=None):\n",
    "        #Load a model from a checkpoint.\"\"\"\n",
    "        model = cls.from_graph(checkpoint, path)\n",
    "        model.load_checkpoint(checkpoint)\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def _define_graph(model_type, input_shape, output_size,\n",
    "                    nn_width, nn_depth, weight_decay, learning_rate):\n",
    "        \n",
    "        # Define the model graph.\n",
    "        # Inference inputs\n",
    "        input_size = int(np.prod(input_shape))\n",
    "        observations = tf.placeholder(tf.float32, [None, input_size], name=\"input\")\n",
    "        legals_mask = tf.placeholder(tf.bool, [None, output_size],\n",
    "                                     name=\"legals_mask\")\n",
    "        training = tf.placeholder(tf.bool, name=\"training\")\n",
    "\n",
    "        bn_updates = []\n",
    "\n",
    "        torso = observations  # Ignore the input shape, treat it as a flat array.\n",
    "        for i in range(nn_depth):\n",
    "            torso = cascade(torso, [\n",
    "                tfkl.Dense(nn_width, name=f\"torso_{i}_dense\"),\n",
    "                tfkl.Activation(\"relu\"),\n",
    "            ])\n",
    "\n",
    "        # The state head\n",
    "        state_head = cascade(torso, [\n",
    "              tfkl.Dense(nn_width, name=\"state_dense\"),\n",
    "              tfkl.Activation(\"relu\"),\n",
    "          ])\n",
    "    \n",
    "        state_logits = tfkl.Dense(output_size, name=\"state\")(state_head)\n",
    "        state_logits = tf.where(legals_mask, state_logits,\n",
    "                                 -1e32 * tf.ones_like(state_logits))\n",
    "        state_softmax = tf.identity(tfkl.Softmax()(state_logits),\n",
    "                                     name=\"state_softmax\")\n",
    "        state_targets = tf.placeholder(\n",
    "            shape=[None, output_size], dtype=tf.float32, name=\"state_targets\")\n",
    "        state_loss = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "                logits=state_logits, labels=state_targets),\n",
    "            name=\"state_loss\")\n",
    "\n",
    "        l2_reg_loss = tf.add_n([\n",
    "            weight_decay * tf.nn.l2_loss(var)\n",
    "            for var in tf.trainable_variables()\n",
    "            if \"/bias:\" not in var.name\n",
    "        ], name=\"l2_reg_loss\")\n",
    "\n",
    "        total_loss = state_loss + l2_reg_loss\n",
    "        \n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "        \n",
    "        with tf.control_dependencies(bn_updates):\n",
    "            train = optimizer.minimize(total_loss, name=\"train\")\n",
    "\n",
    "    @property\n",
    "    def num_trainable_variables(self):\n",
    "        return sum(np.prod(v.shape) for v in tf.trainable_variables())\n",
    "\n",
    "    def print_trainable_variables(self):\n",
    "        for v in tf.trainable_variables():\n",
    "            print(\"{}: {}\".format(v.name, v.shape))\n",
    "\n",
    "    def inference(self, observation, legals_mask):\n",
    "        return self._session.run(\n",
    "                            self._state_softmax,\n",
    "                            feed_dict={self._input: np.array(observation, dtype=np.float32),\n",
    "                               self._legals_mask: np.array(legals_mask, dtype=np.bool),\n",
    "                               self._training: False})\n",
    "\n",
    "    def update(self, train_inputs: Sequence[TrainInput]):\n",
    "        # Runs a training step.\n",
    "        batch = TrainInput.stack(train_inputs)\n",
    "\n",
    "        # Run a training step and get the losses.\n",
    "        _, state_loss, l2_reg_loss = self._session.run(\n",
    "                [self._train, self._state_loss, self._l2_reg_loss],\n",
    "                feed_dict={self._input: batch.observation,\n",
    "                   self._legals_mask: batch.legals_mask,\n",
    "                   self._state_targets: batch.state,\n",
    "                   self._training: True})\n",
    "\n",
    "        return Losses(state_loss, l2_reg_loss)\n",
    "\n",
    "    def save_checkpoint(self, step):\n",
    "        return self._saver.save(\n",
    "            self._session,\n",
    "            os.path.join(self._path, \"checkpoint\"),\n",
    "            global_step=step)\n",
    "\n",
    "    def load_checkpoint(self, path):\n",
    "        return self._saver.restore(self._session, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
