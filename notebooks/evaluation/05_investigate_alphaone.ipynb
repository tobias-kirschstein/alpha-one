{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/d/ownCloud/Uni/Semester Ma 5/Advanced Deep Learning for Robotics (IN2349)/Project/tum-adlr-ws20-9\n"
     ]
    }
   ],
   "source": [
    "%cd ../..\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/envs/alpha_one/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import pyspiel\n",
    "import numpy as np\n",
    "\n",
    "from alpha_one.model.model_manager import AlphaOneCheckpointManager, OpenSpielCheckpointManager, CFRCheckpointManager\n",
    "from alpha_one.utils.play import VerboseGameMachine\n",
    "from alpha_one.utils.mcts import MCTSConfig\n",
    "from alpha_one.utils.mcts_II import IIGMCTSConfig\n",
    "from alpha_one.utils.state_to_value import state_to_value\n",
    "from alpha_one.utils.statemask import get_state_mask\n",
    "from alpha_one.model.agent import DirectInferenceAgent, IIGMCTSAgent, OmniscientAgent, DMCTSAgent, CFRAgent\n",
    "from alpha_one.game.observer import OmniscientObserver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Game Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_name = 'leduc_poker'\n",
    "run_name = 'LP-local-46'\n",
    "\n",
    "game = pyspiel.load_game(game_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Omniscient Observation: [Round 2][Player: -1][Pot: 10][Money: 95 95[Private: 01][Ante: 5 5]\n",
      "Omniscient Observation: [Round 2][Player: 0][Pot: 0][Money: 100 100[Private: 01][Ante: 13 13][Public: 5]\n",
      "Current Player: -4\n",
      "Legal actions: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_machine = VerboseGameMachine(game)\n",
    "game_machine.new_game()\n",
    "game_machine.play_action(0)\n",
    "game_machine.play_action(1)\n",
    "game_machine.play_action(2)\n",
    "game_machine.play_action(2)\n",
    "game_machine.play_action(1)\n",
    "game_machine.get_observations()\n",
    "game_machine.play_action(5)\n",
    "game_machine.play_action(2)\n",
    "game_machine.play_action(2)\n",
    "game_machine.play_action(1)\n",
    "game_machine.get_observations()\n",
    "game_machine.list_player_actions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/tobias/Uni/Semester Ma 5/Advanced Deep Learning for Robotics (IN2349)/Project/model_saves/leduc_poker/LP-local-46-observation_model/checkpoint-18\n",
      "INFO:tensorflow:Restoring parameters from /home/tobias/Uni/Semester Ma 5/Advanced Deep Learning for Robotics (IN2349)/Project/model_saves/leduc_poker/LP-local-46-game_model/checkpoint-18\n"
     ]
    }
   ],
   "source": [
    "model_manager = AlphaOneCheckpointManager(game_name, run_name)\n",
    "observation_model, game_model = model_manager.load_checkpoint(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. AlphaOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_previous_observations = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_one_mcts_config = IIGMCTSConfig(\n",
    "    uct_c=10000,\n",
    "    max_mcts_simulations=100,\n",
    "    temperature=1,\n",
    "    optimism=0.001,\n",
    "    n_previous_observations=3,\n",
    "    use_reward_policy=True,\n",
    "    alpha_one=True,\n",
    "    state_to_value=state_to_value(game_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [],
   "source": [
    "direct_inference_agent = DirectInferenceAgent(observation_model, n_previous_observations=n_previous_observations)\n",
    "alpha_one_agent = IIGMCTSAgent.from_config(game, observation_model, game_model, alpha_one_mcts_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. D-MCTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name_d_mcts = \"LP-DMCTS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/tobias/Uni/Semester Ma 5/Advanced Deep Learning for Robotics (IN2349)/Project/model_saves/leduc_poker/LP-DMCTS/checkpoint-12\n",
      "INFO:tensorflow:Restoring parameters from /home/tobias/Uni/Semester Ma 5/Advanced Deep Learning for Robotics (IN2349)/Project/model_saves/leduc_poker/LP-DMCTS/checkpoint-0\n"
     ]
    }
   ],
   "source": [
    "model_manager_dmcts = OpenSpielCheckpointManager(game_name, run_name_d_mcts)\n",
    "\n",
    "dmcts_model = model_manager_dmcts.load_checkpoint(-1)\n",
    "dmcts_model_untrained = model_manager_dmcts.load_checkpoint(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmcts_mcts_config = MCTSConfig(uct_c=1000, \n",
    "                               max_mcts_simulations=100,\n",
    "                               temperature=1,\n",
    "                               determinized_MCTS=True, \n",
    "                               omniscient_observer=True,\n",
    "                               use_reward_policy=True)\n",
    "\n",
    "d_mcts_agent = DMCTSAgent(dmcts_model, dmcts_mcts_config)\n",
    "d_mcts_agent_untrained = DMCTSAgent(dmcts_model_untrained, dmcts_mcts_config)\n",
    "d_mcts_random_rollout_agent = DMCTSAgent(None, dmcts_mcts_config, n_rollouts=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Omniscient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name_omniscient = \"LP-12\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/tobias/Uni/Semester Ma 5/Advanced Deep Learning for Robotics (IN2349)/Project/model_saves/leduc_poker/LP-12/checkpoint-6\n"
     ]
    }
   ],
   "source": [
    "model_manager_omniscient = OpenSpielCheckpointManager(game_name, run_name_omniscient)\n",
    "\n",
    "omniscient_model = model_manager_omniscient.load_checkpoint(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "omniscient_mcts_config = MCTSConfig(5, 100, 1, use_reward_policy=True, omniscient_observer=True)\n",
    "\n",
    "omniscient_agent_untrained = OmniscientAgent(game, omniscient_mcts_config)\n",
    "omniscient_agent = OmniscientAgent(game, omniscient_mcts_config, model=omniscient_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Blind Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name_blind = \"LP-12-blind-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/tobias/Uni/Semester Ma 5/Advanced Deep Learning for Robotics (IN2349)/Project/model_saves/leduc_poker/LP-12-blind-1/checkpoint-999\n"
     ]
    }
   ],
   "source": [
    "model_manager_blind = OpenSpielCheckpointManager(game_name, run_name_blind)\n",
    "\n",
    "blind_model = model_manager_blind.load_checkpoint(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "blind_agent = DirectInferenceAgent(blind_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. CFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name_cfr = 'LP-CFR-2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager = CFRCheckpointManager(game_name, run_name_cfr)\n",
    "cfr_policy_table = model_manager.load_checkpoint(-1)\n",
    "cfr_agent = CFRAgent(cfr_policy_table, temperature=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Investigate specific Game Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "omniscient_observer = OmniscientObserver(game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_machine = VerboseGameMachine(game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_machine.new_game()\n",
    "\n",
    "game_machine.play_action(5)\n",
    "game_machine.play_action(0)\n",
    "game_machine.play_action(2)\n",
    "game_machine.play_action(1)\n",
    "#game_machine.play_action(1)\n",
    "game_machine.play_action(4)\n",
    "game_machine.play_action(2)\n",
    "#game_machine.play_action(2)\n",
    "#game_machine.play_action(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Player: 1\n",
      "Legal actions: \n",
      "  - 0: Fold\n",
      "  - 1: Call\n",
      "  - 2: Raise\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 771,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_machine.list_player_actions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Direct Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = [game_machine.information_set_generator.get_padded_observation_history(n_previous_observations)]\n",
    "\n",
    "information_set = game_machine.information_set_generator.calculate_information_set()\n",
    "state_mask, _ = get_state_mask(alpha_one_mcts_config.state_to_value, information_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.11920792]], dtype=float32),\n",
       " array([[0.0964878 , 0.38241032, 0.52110183]], dtype=float32)]"
      ]
     },
     "execution_count": 773,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_model.inference([omniscient_observer.get_observation_tensor(information_set[0])], [game_machine.get_state().legal_actions_mask()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [],
   "source": [
    "value, policy = observation_model.inference(obs,  [state_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33953798, 0.06093471, 0.3116335 , 0.28789374], dtype=float32)"
      ]
     },
     "execution_count": 775,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy[0][state_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50686806]], dtype=float32)"
      ]
     },
     "execution_count": 776,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. AlphaOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, array([0.33509969, 0.33509969, 0.32980062]))"
      ]
     },
     "execution_count": 798,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_one_agent.next_move(game_machine.information_set_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.25777950e-03, 2.95529772e-04, 6.03452244e-04, 9.95843238e-01])"
      ]
     },
     "execution_count": 797,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_one_agent.get_last_state_policy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Omniscient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, array([0.97810967, 0.0179147 , 0.00397562]))"
      ]
     },
     "execution_count": 792,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omniscient_agent.next_move(game_machine.get_state())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. D-MCTS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, array([0.89957579, 0.09481459, 0.00560962]))"
      ]
     },
     "execution_count": 793,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_mcts_agent.next_move(game_machine.get_information_set_generator())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. Blind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, array([0.8333642 , 0.08430433, 0.08233147], dtype=float32))"
      ]
     },
     "execution_count": 794,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blind_agent.next_move(game_machine.get_state())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6. CFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, array([0.83984927, 0.00926617, 0.15088456]))"
      ]
     },
     "execution_count": 795,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfr_agent.next_move(game_machine.get_state())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
