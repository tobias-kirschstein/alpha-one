{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../..\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspiel\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from alpha_one.model.model_manager import OpenSpielCheckpointManager, AlphaOneCheckpointManager\n",
    "from alpha_one.model.agent import IIGMCTSAgent, DMCTSAgent, OmniscientAgent, DirectInferenceAgent, RandomAgent\n",
    "from alpha_one.train import MCTSConfig\n",
    "from alpha_one.utils.state_to_value import state_to_value\n",
    "from alpha_one.utils.mcts_II import initialize_bot_alphaone, ii_mcts_agent, IIGMCTSConfig\n",
    "from alpha_one.utils.play import GameMachine\n",
    "from alpha_one.utils.determinized_mcts import initialize_bot, compute_mcts_policy\n",
    "from alpha_one.game.information_set import InformationSetGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Game Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_name = \"leduc_poker\"\n",
    "game = pyspiel.load_game(game_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Setup agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UCT_C = math.sqrt(2)\n",
    "max_mcts_simulations = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. AlphaOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name_alpha_one = \"LP-local-28\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_previous_observations = 3\n",
    "optimism = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager_alpha_one = AlphaOneCheckpointManager(game_name, run_name_alpha_one)\n",
    "\n",
    "observation_model, game_model = model_manager_alpha_one.load_checkpoint(-1)\n",
    "observation_model_untrained, game_model_untrained = model_manager_alpha_one.load_checkpoint(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphaone_mcts_config = IIGMCTSConfig(UCT_C, max_mcts_simulations, 0, None, None, None, \n",
    "                                  alpha_one=True, \n",
    "                                  state_to_value=state_to_value(game_name), use_reward_polic=True, n_previous_observations=n_previous_observations, optimism=optimism)\n",
    "\n",
    "alpha_one_agent = IIGMCTSAgent.from_config(game, observation_model, game_model, alphaone_mcts_config)\n",
    "untrained_alpha_one_agent = IIGMCTSAgent.from_config(game, observation_model_untrained, game_model_untrained, alphaone_mcts_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. D-MCTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name_d_mcts = \"LP-local-6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager_dmcts = OpenSpielCheckpointManager(game_name, run_name_d_mcts)\n",
    "\n",
    "dmcts_model = model_manager_dmcts.load_checkpoint(-1)\n",
    "dmcts_model_untrained = model_manager_dmcts.load_checkpoint(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmcts_mcts_config = MCTSConfig(UCT_C, max_mcts_simulations, 0, None, None, None, \n",
    "                               determinized_MCTS=True, \n",
    "                               omniscient_observer=True)\n",
    "\n",
    "d_mcts_agent = DMCTSAgent(dmcts_model, dmcts_mcts_config)\n",
    "untrained_d_mcts_agent = DMCTSAgent(dmcts_model_untrained, dmcts_mcts_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Omniscient Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name_omniscient = \"LP-local-6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager_omniscient = OpenSpielCheckpointManager(game_name, run_name_omniscient)\n",
    "\n",
    "omniscient_model = model_manager_omniscient.load_checkpoint(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omniscient_mcts_config = MCTSConfig(UCT_C, max_mcts_simulations, 0, use_reward_policy=True, omniscient_observer=True)\n",
    "\n",
    "omniscient_agent_untrained = OmniscientAgent(game, omniscient_mcts_config)\n",
    "omniscient_agent = OmniscientAgent(game, omniscient_mcts_config, model=omniscient_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Blind Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name_blind = \"LP-local-6-blind-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager_blind = OpenSpielCheckpointManager(game_name, run_name_blind)\n",
    "\n",
    "blind_model = model_manager_blind.load_checkpoint(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blind_agent = DirectInferenceAgent(blind_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Random Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_agent = RandomAgent(game)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Player Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Available Agents:\n",
    " - `alpha_one_agent`\n",
    " - `alpha_one_agent_untrained`\n",
    " - `d_mcts_agent`\n",
    " - `d_mcts_agent_untrained`\n",
    " - `omniscient_agent`\n",
    " - `omniscient_agent_untrained`\n",
    " - `blind_agent`\n",
    " - `random_agent`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_setup = {\n",
    "    0: omniscient_agent,\n",
    "    1: omniscient_agent_untrained\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.  Competition with 2 players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_machine = GameMachine(game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_guess = 0\n",
    "incorrect_guess = 0\n",
    "game_returns = []\n",
    "for _ in tqdm(range(100)):\n",
    "    game_machine.new_game()\n",
    "\n",
    "    while not game_machine.is_finished():\n",
    "        player = game_machine.current_player()\n",
    "        agent = player_setup[player]\n",
    "        \n",
    "        if agent.is_information_set_agent():\n",
    "            action, policy = agent.next_move(game_machine.get_information_set_generator())\n",
    "        else:\n",
    "            action, policy = agent.next_move(game_machine.get_state())\n",
    "            \n",
    "        action = np.argmax(policy)\n",
    "        if isinstance(agent, IIGMCTSAgent):\n",
    "            guessed_state = agent.get_last_guessed_state()\n",
    "            if guessed_state.__str__() == game_machine.state.__str__():\n",
    "                correct_guess += 1\n",
    "            else:\n",
    "                incorrect_guess += 1\n",
    "    \n",
    "        game_machine.play_action(action)\n",
    "            \n",
    "    game_returns.append(game_machine.get_rewards())\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_returns = np.array(game_returns)\n",
    "average_return = game_returns.mean(axis=0)\n",
    "print(f\"Average return:\")\n",
    "print(f\"---------------\")\n",
    "print(f\"  {type(player_setup[0]).__name__}: {average_return[0]}\")\n",
    "print(f\"  {type(player_setup[1]).__name__}: {average_return[1]}\")\n",
    "if correct_guess + incorrect_guess > 0:\n",
    "    print(f\" correct guess probability: {correct_guess/(correct_guess+incorrect_guess):0.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
